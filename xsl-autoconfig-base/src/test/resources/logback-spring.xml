<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="false" scanPeriod="30 seconds">
    <!-- 环境变量 -->
	<springProperty scope="context" name="appname" source="spring.application.name" defaultValue=""/>
	<springProperty scope="context" name="logPath" source="logging.path" defaultValue="/openxsl/logs"/>
    <springProperty scope="context" name="logFile" source="logging.file" defaultValue="logback.log"/>
    <springProperty scope="context" name="logLevel" source="logging.level" defaultValue="INFO"/>
    <springProperty scope="context" name="maxHistory" source="logging.maxHistory" defaultValue="365"/>
    <springProperty scope="context" name="logPattern" source="logging.pattern" defaultValue="%d{HH:mm:ss.SSS} [%thread] %-5level %logger [%X{traceId} %X{spanId} %X{parentId}] - %msg%n"/>
    <!-- ConsoleAppender -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder charset="UTF-8">
            <pattern>${logPattern}</pattern>
        </encoder>
    </appender>
    <!-- RollingFileAppender -->
    <appender name="RollingFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${logPath}/${appname}/${logFile}</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${logFile}.%d{yyyy-MM-dd}</fileNamePattern>
            <maxHistory>10</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger [%X{traceId} %X{spanId} %X{parentId}] - %msg%n</pattern>
        </encoder>
    </appender>
    <!--appender name="KafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
	    <encoder class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
	        <layout class="net.logstash.logback.layout.LogstashLayout" >
	            <includeContext>true</includeContext>
	            <includeCallerData>true</includeCallerData>
	            <customFields>{"system":"test"}</customFields>
	            <fieldNames class="net.logstash.logback.fieldnames.ShortenedFieldNames"/>
	        </layout>
	        <charset>UTF-8</charset>
	    </encoder>
	    <producerConfig>bootstrap.servers=localhost:9092</producerConfig>
	    <topic>applog</topic>
	    <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
	    <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
	</appender-->
    <!-- 异步输出 -->
    <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="RollingFile"/>
    </appender>
    
    <!-- dev环境输出到控制台  -->
    <logger name="com.openxsl" additivity="false" level="info">
        <springProfile name="dev">
        	<appender-ref ref="CONSOLE"/>
        </springProfile>
        <appender-ref ref="ASYNC"/>
    </logger>
    <logger name="org.springframework.boot" additivity="false" level="${logLevel}">
        <springProfile name="dev">
        	<appender-ref ref="CONSOLE"/>
        </springProfile>
        <appender-ref ref="ASYNC"/>
    </logger>
    
    <root level="WARN">
    	<springProfile name="dev">
        	<appender-ref ref="CONSOLE"/>
        </springProfile>
        <appender-ref ref="ASYNC"/>
    </root>
</configuration>
